# Parte do Streamlit para visualiza칞칚o interativa
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler


# Implementa칞칚o do SOM
class SOM:
    def __init__(self, som_size, input_dim, lr=0.3, sigma=1.0, random_seed=42):
        self.som_size = som_size
        self.input_dim = input_dim
        self.lr = lr
        self.sigma = sigma
        self.random_seed = random_seed

        # Inicializar os pesos aleatoriamente
        np.random.seed(random_seed)
        self.weights = np.random.rand(som_size, som_size, input_dim)

    def find_bmu(self, x):
        """Encontrar a Best Matching Unit (BMU) para um vetor de entrada x"""
        # Calcular a dist칙ncia euclidiana entre x e todos os neur칪nios
        distances = np.linalg.norm(self.weights - x, axis=2)
        # Encontrar o 칤ndice do neur칪nio com menor dist칙ncia
        bmu_index = np.unravel_index(np.argmin(distances), distances.shape)
        return bmu_index

    def update_weights(self, x, bmu_index, epoch, max_epochs):
        """Atualizar os pesos do SOM"""
        # Calcular a taxa de aprendizado e raio de vizinhan칞a decrescentes
        current_lr = self.lr * (1 - epoch / max_epochs)
        current_sigma = self.sigma * (1 - epoch / max_epochs)

        # Criar grid de coordenadas
        i = np.arange(self.som_size)
        j = np.arange(self.som_size)
        ii, jj = np.meshgrid(i, j, indexing='ij')

        # Calcular dist칙ncias no grid do SOM
        distances = np.sqrt((ii - bmu_index[0]) ** 2 + (jj - bmu_index[1]) ** 2)

        # Calcular a fun칞칚o de vizinhan칞a
        neighborhood = np.exp(-distances ** 2 / (2 * current_sigma ** 2))

        # Atualizar os pesos
        for i in range(self.som_size):
            for j in range(self.som_size):
                influence = neighborhood[i, j] * current_lr
                self.weights[i, j] += influence * (x - self.weights[i, j])

    def train(self, X, max_epochs=700):
        """Treinar o SOM"""
        n_samples = X.shape[0]

        for epoch in range(max_epochs):
            # Embaralhar os dados a cada 칠poca
            indices = np.random.permutation(n_samples)

            for idx in indices:
                x = X[idx]
                # Encontrar BMU
                bmu_index = self.find_bmu(x)
                # Atualizar pesos
                self.update_weights(x, bmu_index, epoch, max_epochs)

            if epoch % 100 == 0:
                print(f"칄poca {epoch}/{max_epochs} conclu칤da")

    def predict(self, X):
        """Atribuir cada amostra a um neur칪nio do SOM"""
        labels = []
        for x in X:
            bmu_index = self.find_bmu(x)
            # Converter coordenadas 2D em um 칰nico label
            label = bmu_index[0] * self.som_size + bmu_index[1]
            labels.append(label)
        return np.array(labels)

    def get_umatrix(self):
        """Calcular a matriz U (Unified Distance Matrix) para visualiza칞칚o"""
        umatrix = np.zeros((self.som_size, self.som_size))

        for i in range(self.som_size):
            for j in range(self.som_size):
                # Calcular dist칙ncias para os vizinhos
                distances = []
                if i > 0:
                    distances.append(np.linalg.norm(self.weights[i, j] - self.weights[i - 1, j]))
                if i < self.som_size - 1:
                    distances.append(np.linalg.norm(self.weights[i, j] - self.weights[i + 1, j]))
                if j > 0:
                    distances.append(np.linalg.norm(self.weights[i, j] - self.weights[i, j - 1]))
                if j < self.som_size - 1:
                    distances.append(np.linalg.norm(self.weights[i, j] - self.weights[i, j + 1]))

                umatrix[i, j] = np.mean(distances) if distances else 0

        return umatrix


def main():
    st.title("An치lise de Clusters - SOM")
    st.write("Visualiza칞칚o interativa dos clusters formados pelo Self-Organizing Map")

    # Carregar os dados
    try:
        df = pd.read_csv('imo.csv')
        st.success("Dados carregados com sucesso!")
        st.write(f"Shape do dataset: {df.shape}")
    except FileNotFoundError:
        st.error("Arquivo 'imo.csv' n칚o encontrado! Verifique se o arquivo est치 no diret칩rio correto.")
        return
    except Exception as e:
        st.error(f"Erro ao carregar arquivo: {e}")
        return

    # Processar dados
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

    if not numeric_cols:
        st.error("N칚o h치 colunas num칠ricas no dataset!")
        return

    X = df[numeric_cols].values

    # Normalizar os dados
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Sidebar com par칙metros
    st.sidebar.header("Par칙metros do SOM")
    som_size = st.sidebar.slider("Tamanho do SOM", 3, 10, 5)
    lr = st.sidebar.slider("Learning Rate", 0.1, 1.0, 0.3)
    max_epochs = st.sidebar.slider("N칰mero de 칄pocas", 100, 1000, 700)
    sigma = st.sidebar.slider("Sigma", 0.1, 2.0, 1.0)

    # Bot칚o para treinar o SOM
    if st.sidebar.button("Treinar SOM"):
        with st.spinner("Treinando o SOM... Isso pode levar alguns instantes."):
            # Criar e treinar o SOM
            input_dim = X_scaled.shape[1]
            som = SOM(som_size, input_dim, lr, sigma, random_seed=42)
            som.train(X_scaled, max_epochs)

            # Fazer previs칫es
            labels = som.predict(X_scaled)
            df['SOM_Cluster'] = labels

            # Salvar o modelo treinado na session state
            st.session_state.som_trained = True
            st.session_state.df_clusterizado = df
            st.session_state.labels = labels

    # Verificar se o SOM foi treinado
    if 'som_trained' in st.session_state and st.session_state.som_trained:
        df = st.session_state.df_clusterizado
        labels = st.session_state.labels

        st.subheader("Distribui칞칚o dos Clusters")
        fig, ax = plt.subplots()
        df['SOM_Cluster'].value_counts().sort_index().plot(kind='bar', ax=ax)
        ax.set_title('Distribui칞칚o de Amostras por Cluster')
        ax.set_xlabel('Cluster')
        ax.set_ylabel('N칰mero de Amostras')
        st.pyplot(fig)

        # Selecionar vari치vel para an치lise
        st.subheader("An치lise por Vari치vel")
        variavel = st.selectbox("Selecione a vari치vel para an치lise:", numeric_cols)

        # Boxplot por cluster
        fig2, ax2 = plt.subplots(figsize=(10, 6))
        df.boxplot(column=variavel, by='SOM_Cluster', ax=ax2)
        plt.title(f'Distribui칞칚o de {variavel} por Cluster')
        plt.suptitle('')  # Remove t칤tulo autom치tico
        st.pyplot(fig2)

        # Estat칤sticas descritivas
        st.subheader("Estat칤sticas por Cluster")
        st.dataframe(df.groupby('SOM_Cluster')[variavel].describe())

        # Matriz U
        st.subheader("Matriz U - Visualiza칞칚o do SOM")
        som = SOM(som_size, X_scaled.shape[1], lr, sigma, 42)
        umatrix = som.get_umatrix()

        fig3, ax3 = plt.subplots()
        im = ax3.imshow(umatrix, cmap='viridis', interpolation='nearest')
        plt.colorbar(im, ax=ax3)
        ax3.set_title('Matriz U - Dist칙ncias M칠dias entre Neur칪nios')
        st.pyplot(fig3)

        # Download dos resultados
        st.subheader("Exportar Resultados")
        csv = df.to_csv(index=False)
        st.download_button(
            label="游닌 Baixar dados clusterizados",
            data=csv,
            file_name="dados_clusterizados_som.csv",
            mime="text/csv"
        )

    else:
        st.info("游녡 Configure os par칙metros e clique em 'Treinar SOM' para iniciar a an치lise.")


if __name__ == "__main__":
    main()