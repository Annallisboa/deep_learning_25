# Parte do Streamlit para visualiza√ß√£o interativa
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler


# Implementa√ß√£o do SOM
class SOM:
    def __init__(self, som_size, input_dim, lr=0.3, sigma=1.0, random_seed=42):
        self.som_size = som_size
        self.input_dim = input_dim
        self.lr = lr
        self.sigma = sigma
        self.random_seed = random_seed

        # Inicializar os pesos aleatoriamente
        np.random.seed(random_seed)
        self.weights = np.random.rand(som_size, som_size, input_dim)

    def find_bmu(self, x):
        """Encontrar a Best Matching Unit (BMU) para um vetor de entrada x"""
        # Calcular a dist√¢ncia euclidiana entre x e todos os neur√¥nios
        distances = np.linalg.norm(self.weights - x, axis=2)
        # Encontrar o √≠ndice do neur√¥nio com menor dist√¢ncia
        bmu_index = np.unravel_index(np.argmin(distances), distances.shape)
        return bmu_index

    def update_weights(self, x, bmu_index, epoch, max_epochs):
        """Atualizar os pesos do SOM"""
        # Calcular a taxa de aprendizado e raio de vizinhan√ßa decrescentes
        current_lr = self.lr * (1 - epoch / max_epochs)
        current_sigma = self.sigma * (1 - epoch / max_epochs)

        # Criar grid de coordenadas
        i = np.arange(self.som_size)
        j = np.arange(self.som_size)
        ii, jj = np.meshgrid(i, j, indexing='ij')

        # Calcular dist√¢ncias no grid do SOM
        distances = np.sqrt((ii - bmu_index[0]) ** 2 + (jj - bmu_index[1]) ** 2)

        # Calcular a fun√ß√£o de vizinhan√ßa
        neighborhood = np.exp(-distances ** 2 / (2 * current_sigma ** 2))

        # Atualizar os pesos
        for i in range(self.som_size):
            for j in range(self.som_size):
                influence = neighborhood[i, j] * current_lr
                self.weights[i, j] += influence * (x - self.weights[i, j])

    def train(self, X, max_epochs=700):
        """Treinar o SOM"""
        n_samples = X.shape[0]

        for epoch in range(max_epochs):
            # Embaralhar os dados a cada √©poca
            indices = np.random.permutation(n_samples)

            for idx in indices:
                x = X[idx]
                # Encontrar BMU
                bmu_index = self.find_bmu(x)
                # Atualizar pesos
                self.update_weights(x, bmu_index, epoch, max_epochs)

            if epoch % 100 == 0:
                print(f"√âpoca {epoch}/{max_epochs} conclu√≠da")

    def predict(self, X):
        """Atribuir cada amostra a um neur√¥nio do SOM"""
        labels = []
        for x in X:
            bmu_index = self.find_bmu(x)
            # Converter coordenadas 2D em um √∫nico label
            label = bmu_index[0] * self.som_size + bmu_index[1]
            labels.append(label)
        return np.array(labels)


def main():
    st.title("An√°lise de Clusters - SOM")
    st.write("Visualiza√ß√£o interativa dos clusters formados pelo Self-Organizing Map")

    # Carregar os dados
    try:
        df = pd.read_csv('imo.csv')
        st.success("Dados carregados com sucesso!")
        st.write(f"Shape do dataset: {df.shape}")
    except FileNotFoundError:
        st.error("Arquivo 'imo.csv' n√£o encontrado! Verifique se o arquivo est√° no diret√≥rio correto.")
        return
    except Exception as e:
        st.error(f"Erro ao carregar arquivo: {e}")
        return

    # Processar dados
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

    if not numeric_cols:
        st.error("N√£o h√° colunas num√©ricas no dataset!")
        return

    X = df[numeric_cols].values

    # Normalizar os dados
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Sidebar com par√¢metros
    st.sidebar.header("Par√¢metros do SOM")
    som_size = st.sidebar.slider("Tamanho do SOM", 3, 10, 5)
    lr = st.sidebar.slider("Learning Rate", 0.1, 0.3, 0.3)
    max_epochs = st.sidebar.slider("N√∫mero de √âpocas", 700, 1000, 1500)
    sigma = st.sidebar.slider("Sigma", 1.0, 2.0, 3.0)

    # Bot√£o para treinar o SOM
    if st.sidebar.button("Treinar SOM"):
        with st.spinner("Treinando o SOM... Isso pode levar alguns instantes."):
            # Criar e treinar o SOM
            input_dim = X_scaled.shape[1]
            som = SOM(som_size, input_dim, lr, sigma, random_seed=42)
            som.train(X_scaled, max_epochs)

            # Fazer previs√µes
            labels = som.predict(X_scaled)
            df['SOM_Cluster'] = labels

            # Salvar o modelo treinado na session state
            st.session_state.som_trained = True
            st.session_state.df_clusterizado = df
            st.session_state.labels = labels
            st.session_state.som_model = som
            st.session_state.scaler = scaler
            st.session_state.numeric_cols = numeric_cols

    # Verificar se o SOM foi treinado
    if 'som_trained' in st.session_state and st.session_state.som_trained:
        df = st.session_state.df_clusterizado
        labels = st.session_state.labels
        som = st.session_state.som_model
        scaler = st.session_state.scaler
        numeric_cols = st.session_state.numeric_cols

        st.subheader("Distribui√ß√£o dos Clusters")
        fig, ax = plt.subplots()
        df['SOM_Cluster'].value_counts().sort_index().plot(kind='bar', ax=ax)
        ax.set_title('Distribui√ß√£o de Amostras por Cluster')
        ax.set_xlabel('Cluster')
        ax.set_ylabel('N√∫mero de Amostras')
        st.pyplot(fig)

        # Selecionar vari√°vel para an√°lise
        st.subheader("An√°lise por Vari√°vel")
        variavel = st.selectbox("Selecione a vari√°vel para an√°lise:", numeric_cols)

        # Boxplot por cluster
        fig2, ax2 = plt.subplots(figsize=(10, 6))
        df.boxplot(column=variavel, by='SOM_Cluster', ax=ax2)
        plt.title(f'Distribui√ß√£o de {variavel} por Cluster')
        plt.suptitle('')  # Remove t√≠tulo autom√°tico
        st.pyplot(fig2)

        # SE√á√ÉO PARA INPUT DE NOVOS DADOS
        st.subheader("üîÆ Prever Cluster para Novos Dados")

        st.write("Insira os valores para as vari√°veis num√©ricas:")

        # Criar inputs para cada vari√°vel num√©rica
        novos_dados = {}
        col1, col2 = st.columns(2)

        with col1:
            for i, coluna in enumerate(numeric_cols[:len(numeric_cols) // 2]):
                novos_dados[coluna] = st.number_input(
                    f"{coluna}",
                    value=float(df[coluna].mean()),
                    key=f"input_{i}"
                )

        with col2:
            for i, coluna in enumerate(numeric_cols[len(numeric_cols) // 2:]):
                idx = i + len(numeric_cols) // 2
                novos_dados[coluna] = st.number_input(
                    f"{coluna}",
                    value=float(df[coluna].mean()),
                    key=f"input_{idx}"
                )

        # Bot√£o para prever
        if st.button("Prever Cluster"):
            # Criar array com os novos dados
            X_novo = np.array([[novos_dados[col] for col in numeric_cols]])

            # Normalizar os novos dados usando o scaler treinado
            X_novo_scaled = scaler.transform(X_novo)

            # Prever o cluster
            cluster_predito = som.predict(X_novo_scaled)[0]

            # Mostrar resultado
            st.success(f"üéØ **O novo dado pertence ao Cluster: {cluster_predito}**")

            # Mostrar informa√ß√µes sobre o cluster
            st.subheader(f"Informa√ß√µes do Cluster {cluster_predito}")
            cluster_data = df[df['SOM_Cluster'] == cluster_predito]

            st.write(f"**N√∫mero de amostras neste cluster:** {len(cluster_data)}")
            st.write("**Estat√≠sticas descritivas do cluster:**")
            st.dataframe(cluster_data[numeric_cols].describe())

            # Comparar com a m√©dia geral
            st.write("**Compara√ß√£o com a m√©dia geral:**")
            comparacao = pd.DataFrame({
                'M√©dia Geral': df[numeric_cols].mean(),
                'M√©dia do Cluster': cluster_data[numeric_cols].mean(),
                'Diferen√ßa': cluster_data[numeric_cols].mean() - df[numeric_cols].mean()
            })
            st.dataframe(comparacao)

        # Download dos resultados
        st.subheader("Exportar Resultados")
        csv = df.to_csv(index=False)
        st.download_button(
            label="üì• Baixar dados clusterizados",
            data=csv,
            file_name="dados_clusterizados_som.csv",
            mime="text/csv"
        )

    else:
        st.info("üëÜ Configure os par√¢metros e clique em 'Treinar SOM' para iniciar a an√°lise.")


if __name__ == "__main__":
    main()